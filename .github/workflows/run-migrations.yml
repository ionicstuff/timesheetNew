name: DB Migrations

on:
  workflow_dispatch:
    inputs:
      migration:
        description: "Which migration script to run (apply or baseline)"
        required: true
        default: apply

jobs:
  run-migration:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: ap-south-1
      ECS_CLUSTER_NAME: myapp-cluster
      TASK_DEFINITION: myapp-task
      CONTAINER_NAME: myapp-container
      SUBNETS: (subnet-0edf2dbee72fe373b,subnet-018e2886e7ca1a98d,subnet-0c0160cb1bfaba1cf)
      SECURITY_GROUPS: sg-0416d844a13f4199a
      RDS_INSTANCE_ID: myapp-database.cl282y08qf6r.ap-south-1.rds.amazonaws.com
      DB_NAME: myapp_production
      DB_USER: myapp_user
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}

      - name: Choose migration script
        id: pick
        run: |
          if [ "${{ github.event.inputs.migration }}" = "baseline" ]; then
            echo "script=migrations/baseline.js" >> "$GITHUB_OUTPUT"
          else
            echo "script=migrations/apply.js" >> "$GITHUB_OUTPUT"
          fi

      - name: Create DB snapshot (optional)
        if: always()
        id: snapshot
        run: |
          # Example: create a snapshot of the RDS instance before running migrations.
          # This step is optional and can be removed if not needed.
          SNAPSHOT_ID="pre-migration-$(date +%Y%m%d%H%M%S)"
          aws rds create-db-snapshot \
            --db-snapshot-identifier "$SNAPSHOT_ID" \
            --db-instance-identifier "${{ env.RDS_INSTANCE_ID }}"
          echo "snapshot_id=$SNAPSHOT_ID" >> "$GITHUB_OUTPUT"

      - name: Resolve DB host (placeholder)
        id: dbinfo
        run: |
          # Replace this with your method to obtain DB host/endpoint.
          # Example using aws rds describe-db-instances:
          DB_HOST=$(aws rds describe-db-instances \
            --db-instance-identifier "${{ env.RDS_INSTANCE_ID }}" \
            --query 'DBInstances[0].Endpoint.Address' --output text)
          echo "db_host=$DB_HOST" >> "$GITHUB_OUTPUT"
          echo "db_name=${{ env.DB_NAME }}" >> "$GITHUB_OUTPUT"
          echo "db_user=${{ env.DB_USER }}" >> "$GITHUB_OUTPUT"

      - name: Run migration task on ECS Fargate
        id: run-task
        run: |
          # Build container overrides JSON. This runs node <script> inside the container.
          overrides=$(
            jq -c -n \
              --arg name "${{ env.CONTAINER_NAME }}" \
              --arg script "${{ steps.pick.outputs.script }}" \
              --arg dbhost "${{ steps.dbinfo.outputs.db_host }}" \
              --arg dbname "${{ steps.dbinfo.outputs.db_name }}" \
              --arg dbuser "${{ steps.dbinfo.outputs.db_user }}" \
              '{containerOverrides:[{name:$name, command:["node",$script], environment:[ {name:"NODE_ENV",value:"production"},{name:"DB_HOST",value:$dbhost},{name:"DB_NAME",value:$dbname},{name:"DB_USER",value:$dbuser} ]}]}'
          )

          TASK_ARN=$(aws ecs run-task \
            --cluster "${{ env.ECS_CLUSTER_NAME }}" \
            --task-definition "${{ env.TASK_DEFINITION }}" \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[${{ env.SUBNETS }}],securityGroups=[${{ env.SECURITY_GROUPS }}],assignPublicIp=DISABLED}" \
            --overrides "$overrides" \
            --query 'tasks[0].taskArn' --output text)

          if [ -z "$TASK_ARN" ] || [ "$TASK_ARN" = "None" ]; then
            echo "Failed to start ECS task" >&2
            exit 1
          fi

          echo "task_arn=$TASK_ARN" >> "$GITHUB_OUTPUT"

      - name: Wait for task to stop
        run: |
          TASK_ARN="${{ steps.run-task.outputs.task_arn }}"
          aws ecs wait tasks-stopped --cluster "${{ env.ECS_CLUSTER_NAME }}" --tasks "$TASK_ARN"

      - name: Get task exit code and assert success
        run: |
          TASK_ARN="${{ steps.run-task.outputs.task_arn }}"
          TASK_ID=$(basename "$TASK_ARN")
          # Get container exit code (may vary if using multiple containers)
          EXIT_CODE=$(aws logs describe-log-streams \
            --log-group-name "/ecs/${{ env.CONTAINER_NAME }}" \
            --query 'logStreams[?contains(logStreamName, `'"$TASK_ID"'`) == `true`].logStreamName' \
            --output text || true)

          # Optionally fetch and show logs (best-effort)
          if [ -n "$EXIT_CODE" ]; then
            aws logs get-log-events --log-group-name "/ecs/${{ env.CONTAINER_NAME }}" \
              --log-stream-name "$EXIT_CODE" --max-items 200 || true
          fi

          # Note: Determining the container exit code reliably requires describing the task:
          DESCRIBE_JSON=$(aws ecs describe-tasks --cluster "${{ env.ECS_CLUSTER_NAME }}" --tasks "$TASK_ARN")
          # Try to extract the exit code of the first container
          EXIT_CODE=$(echo "$DESCRIBE_JSON" | jq -r '.tasks[0].containers[0].exitCode // "null"')
          if [ "$EXIT_CODE" = "null" ]; then
            echo "Could not determine exit code; failing to be safe." >&2
            exit 1
          fi

          if [ "$EXIT_CODE" -ne 0 ]; then
            echo "Migration task failed with exit code $EXIT_CODE" >&2
            exit $EXIT_CODE
          fi

      - name: Done
        run: echo "Migration completed successfully"
